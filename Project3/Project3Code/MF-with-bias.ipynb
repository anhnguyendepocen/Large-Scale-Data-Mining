{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Q24-25\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import Reader, Dataset, SVD, accuracy\n",
    "from surprise.model_selection import cross_validate, KFold, train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score \n",
    "\n",
    "# Define the format\n",
    "reader = Reader(line_format=\"user item rating timestamp\", sep=',',skip_lines=1)\n",
    "# Load the data from the file using the reader format\n",
    "data = Dataset.load_from_file('ml-latest-small/ratings.csv', reader=reader)\n",
    "\n",
    "meanRMSE = []\n",
    "meanMAE = []\n",
    "\n",
    "for k in np.arange(2, 51, 2):\n",
    "    print \"------------------For k=\",k,\"--------------------\"\n",
    "    algo = SVD(n_factors = k, random_state = 37)\n",
    "    ans=cross_validate(algo, data, cv=10, verbose=True)\n",
    "    meanRMSE.append(np.mean(ans.get('test_rmse')))\n",
    "    meanMAE.append(np.mean(ans.get('test_mae')))\n",
    "    \n",
    "kvals = np.arange(2, 51, 2)\n",
    "plt.plot(kvals, meanRMSE)\n",
    "plt.title(\"Average RMSE vs Number of latent factors\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(kvals, meanMAE)\n",
    "plt.title(\"Average MAE vs Number of latent factors\")\n",
    "plt.show()\n",
    "\n",
    "plt.xlabel(\"Number of latent factors\")\n",
    "plt.ylabel(\"Average Error\")\n",
    "plt.title(\"Average Error vs Number of latent factors\")\n",
    "plt.plot(kvals, meanRMSE)\n",
    "plt.plot(kvals, meanMAE)\n",
    "plt.legend([\"Avg RMSE\", \"Avg MAE\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Q26 (Popular Movies)\n",
    "\n",
    "# define a cross-validation iterator\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "meanRMSE1 = []\n",
    "\n",
    "for k in np.arange(2, 51, 2):\n",
    "    print \"------------------For k=\",k,\"--------------------\"\n",
    "    algo = SVD(n_factors = k, random_state = 37)\n",
    "    rmse = []\n",
    "    for trainset, testset in kf.split(data):\n",
    "        algo.fit(trainset)\n",
    "        newtest = getPopular(testset, 2)\n",
    "        predictions = algo.test(newtest)\n",
    "        rmse.append(accuracy.rmse(predictions))\n",
    "    meanRMSE1.append(round(np.mean(rmse),4))\n",
    "\n",
    "plt.xlabel(\"Number of latent factors\")\n",
    "plt.ylabel(\"Average RMSE\")\n",
    "plt.title(\"Popular Movies \\nAverage RMSE vs Number of latent factors\")\n",
    "plt.plot(kvals, meanRMSE1)\n",
    "plt.ylim([0.8,0.9])\n",
    "plt.show()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Q27 (Unpopular Movies)\n",
    "meanRMSE2 = []\n",
    "\n",
    "for k in np.arange(2, 51, 2):\n",
    "    print \"------------------For k=\",k,\"--------------------\"\n",
    "    algo = SVD(n_factors = k, random_state = 37)\n",
    "    rmse = []\n",
    "    for trainset, testset in kf.split(data):\n",
    "        algo.fit(trainset)\n",
    "        newtest = getUnpopular(testset, 2)\n",
    "        predictions = algo.test(newtest)\n",
    "        rmse.append(accuracy.rmse(predictions))\n",
    "    meanRMSE2.append(round(np.mean(rmse),4))\n",
    "\n",
    "plt.xlabel(\"Number of latent factors\")\n",
    "plt.ylabel(\"Average RMSE\")\n",
    "plt.title(\"Unpopular Movies \\n Average RMSE vs Number of latent factors\")\n",
    "plt.plot(kvals, meanRMSE2)\n",
    "plt.ylim([0.8,1.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Q28 (High Variance Movies)\n",
    "meanRMSE3 = []\n",
    "\n",
    "for k in np.arange(2, 51, 2):\n",
    "    print \"------------------For k=\",k,\"--------------------\"\n",
    "    algo = SVD(n_factors = k, random_state = 37)\n",
    "    rmse = []\n",
    "    for trainset, testset in kf.split(data):\n",
    "        algo.fit(trainset)\n",
    "        newtest = getHighVariance(testset)\n",
    "        predictions = algo.test(newtest)\n",
    "        rmse.append(accuracy.rmse(predictions))\n",
    "    meanRMSE3.append(round(np.mean(rmse),4))\n",
    "\n",
    "plt.xlabel(\"Number of latent factors\")\n",
    "plt.ylabel(\"Average RMSE\")\n",
    "plt.title(\"High Variance \\n Average RMSE vs Number of latent factors\")\n",
    "plt.plot(kvals, meanRMSE3)\n",
    "plt.ylim([1.1,1.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Q29\n",
    "def classifyData(testarray, k):\n",
    "    test = []\n",
    "    for i in range(len(testarray)):\n",
    "        test.append(0) if float(testarray[i])<k else test.append(1)\n",
    "    return test\n",
    "\n",
    "def plot_roc(actual, predicted, classifier_name):\n",
    "    x, y, _ = roc_curve(actual, predicted)\n",
    "    plt.plot(x, y, label=\"ROC Curve\")\n",
    "    plt.plot([0, 1], [0, 1])\n",
    "\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.2])\n",
    "\n",
    "    plt.xlabel('False Positive Rate (FPR)')\n",
    "    plt.ylabel('True Positive Rate (TPR)')\n",
    "    plt.title(classifier_name)\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "    \n",
    "threshold = [2.5, 3, 3.5, 4]\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.1, random_state=42)\n",
    "algo = SVD(n_factors = 14, random_state = 37)\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "testarray = np.array(testset)[:,2]\n",
    "\n",
    "for k in threshold:\n",
    "    print '--------------------Threshold=', k,'-----------------------'\n",
    "    test = classifyData(testarray, k)\n",
    "    pred = np.array(predictions)[:,3]\n",
    "    plot_roc(test, pred, \"MF with bias\")\n",
    "    \n",
    "    auc = roc_auc_score(test,pred)\n",
    "    print 'Area under ROC = ', auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Q38\n",
    "def getPR(predictions,k):\n",
    "    userliked = defaultdict(list)\n",
    "    actualliked=defaultdict(list)\n",
    "    al=defaultdict(list)\n",
    "    ul=defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        userliked[uid].append((iid, est))\n",
    "        actualliked[uid].append((iid,true_r))\n",
    "\n",
    "    for uid, user_ratings in userliked.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        #u=filter(lambda x:x[1]>3,user_ratings)\n",
    "        u=map(lambda x:x[0],user_ratings)\n",
    "        if len(u)>0:\n",
    "            ul[uid] = u\n",
    "    for uid, user_ratings in actualliked.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        u=filter(lambda x:x[1]>3,user_ratings)\n",
    "        u=map(lambda x:x[0],u)\n",
    "        if len(u)>0:\n",
    "            al[uid] = u\n",
    "    valid_users=[]\n",
    "    map(lambda x:valid_users.append(x) ,al.keys())\n",
    "    count=0\n",
    "    prec=0\n",
    "    rec=0\n",
    "    recall=[]\n",
    "    precision=[]\n",
    "    for u in valid_users:\n",
    "        if len(ul.get(u))>=k:\n",
    "            prec=prec+(len(set(al.get(u))&set(ul.get(u)[:k]))*1.0/k)\n",
    "            rec=rec+(len(set(al.get(u))&set(ul.get(u)[:k]))*1.0/len(al.get(u)))\n",
    "            precision.append((len(set(al.get(u))&set(ul.get(u)[:5]))*1.0/k))\n",
    "            recall.append((len(set(al.get(u))&set(ul.get(u)[:5]))*1.0/len(al.get(u))))\n",
    "            count=count+1\n",
    "    return prec/count,rec/count\n",
    "\n",
    "\n",
    "\n",
    "recall=[]\n",
    "precision=[]\n",
    "for i in range(1,26):\n",
    "    print \"Computing for k=\",i\n",
    "    prec=0\n",
    "    rec=0\n",
    "\n",
    "    for trainset, testset in kf.split(data):\n",
    "        algo.fit(trainset)\n",
    "        predictions = algo.test(testset)\n",
    "        p,r=getPR(predictions,i)\n",
    "        prec=prec+p\n",
    "        rec=rec+r\n",
    "    precision.append(prec/10)\n",
    "    recall.append(rec/10)\n",
    "    print precision\n",
    "    print recall\n",
    "    \n",
    "plt.xlabel(\"Number of recommendations\")\n",
    "plt.ylabel(\"Average Precision\")\n",
    "plt.title(\"Average Precision vs Number of recommendations \\n for MF with bias\")\n",
    "plt.plot(tvals, precision)\n",
    "plt.show()\n",
    "\n",
    "plt.xlabel(\"Number of recommendations\")\n",
    "plt.ylabel(\"Average Recall\")\n",
    "plt.title(\"Average Recall vs Number of recommendations \\n for MF with bias\")\n",
    "plt.plot(tvals, recall)\n",
    "plt.show()\n",
    "\n",
    "plt.xlabel(\"Number of recommendations\")\n",
    "plt.title(\"Average Precision vs Number of recommendations \\n for MF with bias\")\n",
    "plt.plot(tvals, precision)\n",
    "plt.plot(tvals, recall)\n",
    "plt.legend([\"Precision\", \"Recall\"])\n",
    "plt.show()\n",
    "\n",
    "plt.xlabel(\"Average Recall\")\n",
    "plt.ylabel(\"Average Precision\")\n",
    "plt.title(\"Precision - Recall curve for MF with bias\")\n",
    "plt.plot(recall, precision)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
